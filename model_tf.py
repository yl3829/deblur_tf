import tensorflow as tf
import numpy as np
from utils import res_block

class deblur_model():
    def __init__(self, 
                 d_param,
                 g_param,
                 LAMBDA_A = 100
                 ):
        # input:
        #   d_param(dict): parameters need for discriminator 
        #   g_param(dict): parameters need for generator
        self.d_param = d_param
        self.h_param = g_param
        self.LAMBDA_A = LAMBDA_A
        self.generator_model()
        self.discriminator_model()
        self.init_loss()
    
    def generator_model(self):
        # built the generator model 
        input_size = self.g_param.input_size
        ngf = self.g_param.ngf
        n_downsampling =  self.g_param.n_downsampling
        output_nc = self.g_param.output_nc
        n_blocks_gen = self.g_param.n_blocks_gen

        with tf.VariableScope('g_model'):
            self.real_A = tf.placeholder(dtype=tf.float32, shape=[None,None,None,3], name='real_A')
            g_input = self.real_A

            _out = tf.pad( g_input, [ [0, 0], [3, 3], [3, 3], [0, 0] ], padding = 'REFLECTION' )
            _out = tf.layers.conv2d(_out, filters=ngf, kernel_size=(7,7), strides=(2,2), padding='VALID')
            _out = tf.layers.batch_normalization(_out)
            _out = tf.nn.relu(features=_out)

            for i in range(n_downsampling):
                mult = 2**i
                _out = tf.layers.conv2d(_out, filters=ngf*mult*2, kernel_size=(3, 3), strides=(2, 2), padding='SAME')
                _out = tf.layers.batch_normalization(_out)
                _out = tf.nn.relu(features=_out)

            mult = 2**n_downsampling
            for i in range(n_blocks_gen):
                _out = res_block(_out, ngf*mult, use_dropout=True)

            for i in range(n_downsampling):
                mult = 2**(n_downsampling - i)
                _out = tf.layers.conv2d(_out, filters=int(ngf * mult / 2), kernel_size=(3, 3), strides=(2, 2), padding='SAME')
                _out = tf.layers.batch_normalization(_out)
                _out = tf.nn.relu(features=_out)

            _out = tf.pad( _out, [ [0, 0], [3, 3], [3, 3], [0, 0] ], padding = 'REFLECTION' )
            _out = tf.layers.conv2d(_out, filters=output_nc, kernel_size=(7,7), strides=(2,2), padding='VALID')
            _out = tf.nn.tanh(features=_out)

            _out = tf.add(_out, g_input)

            _out = tf.clip_by_value( _out, clip_value_min = -1, clip_value_max = 1 )

            self.fake_B = _out


        # output
        #    self.fake_B
        # self.real_A = # a place for the input of blury image
        # # implementations
        # # ...
        
        # self.fake_B = # a tensor for the output of the generator_model
        # pass
    
    def discriminator_model(self):
        # take input from self.fake_B and self.real_B
        # output the result of discrrminator
        input_size = self.d_param.input_size
        ndf = self.d_param.ndf
        kernel_size = self.d_param.kernel_size
        n_layers = self.d_param.n_layers
        
        with tf.VariableScope('d_model'):
            alpha = tf.random_uniform(1)
            
            self.real_B = tf.placeholder(tf.float32, [None,input_size,input_size,3], name='real_B') # a placeholder for the real sharp image
            self.interpolates = alpha * self.real_B + (1-alpha) * self.fake_B
            
            d_input = tf.concat([self.fake_B,self.real_B,self.interpolates],0)
            bs = tf.shape(self.fake_B)[0]
            
            _out = tf.layers.conv2d(d_input, filters=ndf, kernel_size=kernel_size, strides=(2,2), padding='same')
            _out = tf.nn.leaky_relu(features=_out, alpha=0.2)
            
            for n in range(1,n_layers):
                nf_mulf = min(2**n, 8)
                
                _out = tf.layers.conv2d(_out, filters=ndf*nf_mulf, kernel_size=kernel_size, strides=(2,2), padding='same')
                _out = tf.layers.batch_normalization(_out)
                _out = tf.nn.leaky_relu(features=_out, alpha=0.2)
            
            nf_mulf = min(2**n_layers, 8)
            _out = tf.layers.conv2d(_out, filters=ndf*nf_mulf, kernel_size=kernel_size, strides=(1,1), padding='same')
            _out = tf.layers.batch_normalization(_out)
            _out = tf.nn.leaky_relu(features=_out, alpha=0.2)
            
            self.fake_D = _out[:bs]
            self.real_D = _out[bs:2*bs]
            self.disc_interpolates = _out[2*bs:]

    
    def wgangp_loss(self,LAMBDA=10):
        # input:
        #    fake_D: a tensor generated by d model used generated images
        #    real_D: a tensor generated by d model used real sharp images
        # return:
        #    d_loss: loss for discriminator
        #    g_gan_loss: loss for generator
        self.g_gan_loss = -tf.reduce_mean(self.fake_D)
        
        grad = tf.gradients(self.disc_interpolates,self.interpolates)
        gradient_penalty = tf.reduce_mean((tf.norm(grad, ord=2, axis=1)-1) ** 2) * LAMBDA
        self.d_loss = tf.reduce_mean(self.fake_D_) - tf.reduce_mean(self.real_D) + gradient_penalty
        
    
    def preceptual_loss(self):
        # input:
        #    fake_B: a tensor generated by generator_model
        #    real_B: a place holder for the real sharp image 
        # return:
        #    p_loss: the preceptual loss for generator
        _in = tf.concat([self.fake_B,self.real_B],axis=0)
        bs = tf.shape(self.fake_B)[0]
        vgg = tf.keras.applications.VGG16(include_top=False, weights='imagenet', input_shape=(256,256,3), input_tensor=_in)
        vgg.trainable = False
        _out = vgg.vgg.get_layer('block3_conv3').output
        self.p_loss = tf.losses.mean_squared_error(_out[bs:],_out[:bs])
    
    def init_loss(self):
        # combine the loss of g model and d model 
        # and apply them to two different optimizer.
        self.wgangp_loss()
        self.preceptual_loss()
        self.g_loss = self.LAMBDA_A*self.g_gan_loss + self.p_loss
        
        # get the variables in discriminator and generator
        tvars = tf.trainable_variables()
        
        d_vars = [var for var in tvars if 'd_model' in var.name]
        g_vars = [var for var in tvars if 'g_model' in var.name]
        
        self.D_trainer = tf.train.AdamOptimizer().minimize(self.d_loss, var_list=d_vars)
        self.G_trainer = tf.train.AdamOptimizer().minimize(self.g_loss, var_list=g_vars)
    
    def train(self):
        # implement training on two models
        pass
    
    def generate(self):
        # generate deblured image
        pass